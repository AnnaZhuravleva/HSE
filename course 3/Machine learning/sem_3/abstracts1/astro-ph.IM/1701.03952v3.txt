In this paper we compare the performance of two likelihood ratio based detection statistics namely maximum likelihood ratio statistic and {\it hybrid} statistic designed for the detection of gravitational waves from compact binary coalescence using multiple interferometric detector networks. We perform simulations with non-spinning double neutron star binary system and neutron star-black hole binary systems with spinning as well as non-spinning black hole component masses. The binary injections are distributed uniformly in volume up to 1 Gpc. We observe that, on average, the maximum likelihood ratio statistic recovers $\sim 34.45\%$, $\sim 49.69\%$, $\sim 61.25\%$ and $\sim 69.67\%$ of injections in 2, 3, 4 and 5 detector networks respectively in the case of neutron star-black hole injections for a fixed false alarm probability of $10^{-7}$ in Gaussian noise. Further, we note that, compared to the maximum likelihood ratio statistic, the {\it hybrid} statistic recovers $\sim 7.45\%$, $\sim 4.57\%$, $\sim 2.56\%$ and $\sim 1.22\%$ more injections in 2, 3, 4 and 5 detector networks respectively for the same false alarm probability in Gaussian noise. On the other hand, among binary neutron star injections, the maximum likelihood ratio statistic recovers $\sim 5.587\%$, $\sim 9.917\%$, $\sim 14.73\%$ and $\sim 19.86\%$ of injections in 2, 3, 4 and 5 detector networks respectively and the {\it hybrid} statistic recovers $\sim 14.63\%$, $\sim 12.91\%$, $\sim 11.49\%$ and $\sim 10.29\%$ more injections compared to maximum likelihood ratio statistic in 2, 3, 4 and 5 detector networks respectively.