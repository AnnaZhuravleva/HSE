One of the most important problems in linear optics quantum computing is to find the origin of its computational complexity. We claim in this work that the majorization of photon distributions is a crucial factor that affects the complexity of linear optics. Our analysis concentrates on the boson sampling problem, an exemplary model of linear optics. Prior to the main discussion, a majorization-dependent quantity that can measure the quantum complexity of identical particle distributions is introduced, which we call the Boltzmann entropy of elementary quantum complexity $S_B^q$. It decreases as the majorization of the photon distribution vector increases. Using the properties of majorization and $S_B^q$, we analyze two quantities that are the criteria for the computational complexity, $\mathcal{T}$ (the runtime of a generalized classical algorithm for calculating the permanent) and $\mathcal{E}$ (the additive error bound for an approximated permanent estimator). The runtime $\mathcal{T}$ becomes shorter as the input and output distribution vectors are more majorized, and the error bound $\mathcal{E}$ decreases as the majorization difference of input and output states increases. In addition, $S_B^q$ turns out to be an underlying quantity of $\mathcal{T}$ and $\mathcal{E}$, which implies that $S_B^q$ is an essential resource of the computational complexity of linear optics. We expect our findings would provide a fresh perspective to answer the fundamental questions of quantum supremacy.