In the context of ultra-fast quantum communication and random number generation, detection timing-jitters represent a strong limitation as they can introduce major time-tagging errors and affect the quality of time-correlated photon counting or quantum state engineering. Despite their importance in emerging photonic quantum technologies, no detector model including such effects has been developed so far. We propose here an operational theoretical model based on POVM density formalism able to explicitly quantify the effect of timing-jitter for a typical class of single photon detector. We apply our model to some common experimental situations.