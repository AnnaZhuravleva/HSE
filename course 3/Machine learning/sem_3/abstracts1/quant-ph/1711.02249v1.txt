Current approaches to fault-tolerant quantum computation will not enable useful quantum computation on near-term devices of 50 to 100 qubits. Leading proposals, such as the color code and surface code schemes, must devote a large fraction of their physical quantum bits to quantum error correction. Building from recent quantum machine learning techniques, we propose an alternative approach to quantum error correction aimed at reducing this overhead, which can be implemented in existing quantum hardware and on a myriad of quantum computing architectures. This method aims to optimize the average fidelity of encoding and recovery circuits with respect to the actual noise in the device, as opposed to that of an artificial or approximate noise model. The quantum variational error corrector (QVECTOR) algorithm employs a quantum circuit with parameters that are variationally-optimized according to processed data originating from quantum sampling of the device, so as to learn encoding and error-recovery gate sequences. We develop this approach for the task of preserving quantum memory and analyze its performance with simulations. We find that, subject to phase damping noise, the simulated QVECTOR algorithm learns a three-qubit encoding and recovery which extend the effective T2 of a quantum memory six-fold. Subject to a continuous-time amplitude- plus phase-damping noise model on five qubits, the simulated QVECTOR algorithm learns encoding and decoding circuits which exploit the coherence among Pauli errors in the noise model to outperform the five-qubit stabilizer code and any other scheme that does not leverage such coherence. Both of these schemes can be implemented with existing hardware.