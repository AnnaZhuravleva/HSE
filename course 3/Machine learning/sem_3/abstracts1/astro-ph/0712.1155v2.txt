A study of the time sequence of optical colours of a large sample of nearby Type Ia supernovae (SNe Ia) is presented. We study the dependence of the colour time evolution with respect to the lightcurve shape, parametrized by the stretch factor. We fit the spectral template that minimizes the colour dispersion in SNe Ia, as measured through UBVRI photometry of near-by supernovae. A clear colour dependence upon lightcurve shape is found, with the narrower lightcurves being redder up to about one month past lightcurve maximum. We also derive an average reddening law, after correcting for lightcurve shape differences in intrinsic colour, that is well described by a Cardelli, Clayton & Mathis law with R_V=1.75 \pm 0.27 for 80 Type Ia supernovae with E(B-V) < 0.7 mag. A subset sample including 69 SNe with modest reddening, E(B-V)<0.25 mag, yields a significantly smaller value, R_V ~ 1, suggesting that the observed reddening of Type Ia supernovae may have a more complex origin, perhaps involving other processes beside extinction by interstellar dust in the host galaxy.