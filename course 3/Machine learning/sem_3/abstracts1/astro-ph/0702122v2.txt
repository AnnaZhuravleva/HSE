Using a sample of gamma-ray burst (GRB) afterglows detected by both the X-Ray and the UV/Optical Telescopes (XRT and UVOT) on Swift, we modelled the spectral energy distributions (SEDs) to determine gas column densities and dust extinction in the GRB local environment. In six out of seven cases we find an X-ray absorber associated with the GRB host galaxy with column density (assuming solar abundances) ranging from (0.8 - 7.7)x10^{21}cm^{-2}. We determine the rest-frame visual extinction A_V using the SMC, LMC and Galactic extinction curves to model the dust in the GRB host galaxy, and this ranges from A_V = 0.12\pm 0.04 to A_V = 0.65^{+0.08}_{-0.07}. The afterglow SEDs were typically best fit by a model with an SMC extinction curve. In only one case was the GRB afterglow better modelled by a Galactic extinction curve, which has a prominent absorption feature at 2175angstrom. We investigate the selection effects present in our sample and how these might distort the true distribution of A_V in GRB host galaxies. We estimate that GRBs with no afterglow detected blueward of 5500angstrom have average rest-frame visual extinctions almost eight times those observed in the optically bright population of GRBs. This may help account for the ~1/3 of GRBs observed by Swift that have no afterglow detected by UVOT.