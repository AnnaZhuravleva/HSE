We present a comparison between simulation results and X-ray observational data on the evolution of the metallicity of the intra-cluster medium (ICM). The simulations of galaxy clusters were performed with the Tree-SPH Gadget2 code that includes a detailed model of chemical evolution, by assuming three different shapes for the stellar initial mass function (IMF), namely the Salpeter (1955), Kroupa (2001) and Arimoto-Yoshii (1987) IMF. Our simulations predict significant radial gradients of the Iron abundance, which extend over the whole cluster virialized region. At larger radii, we do not detect any flattening of the metallicity profiles. As for the evolution of the ICM metal (Iron) abundance out to z=1, we find that it is determined by the combined action of (i) the sinking of already enriched gas, (ii) the ongoing metal production in galaxies and (iii) the locking of ICM metals in newborn stars. As a result, rather than suppressing the metallicity evolution, stopping star formation at z=1 has the effect of producing an even too fast evolution of the emission-weighted ICM metallicity with too high values at low redshift. Finally, we compare simulations with the observed rate of type-Ia supernovae per unit B-band luminosity (SnU_B). We find that our simulated clusters do not reproduce the decreasing trend of SnU_B at low redshift, unless star formation is truncated at z=1.