In this study we investigate the formation and properties of prestellar and protostellar cores using hydrodynamic, self-gravitating Adaptive Mesh Refinement simulations, comparing the cases where turbulence is continually driven and where it is allowed to decay. We model observations of these cores in the C$^{18}$O$(2\to 1)$, NH$_3(1,1)$, and N$_2$H$^+(1\to 0)$ lines, and from the simulated observations we measure the linewidths of individual cores, the linewidths of the surrounding gas, and the motions of the cores relative to one another. Some of these distributions are significantly different in the driven and decaying runs, making them potential diagnostics for determining whether the turbulence in observed star-forming clouds is driven or decaying. Comparing our simulations with observed cores in the Perseus and $\rho$ Ophiuchus clouds shows reasonably good agreement between the observed and simulated core-to-core velocity dispersions for both the driven and decaying cases. However, we find that the linewidths through protostellar cores in both simulations are too large compared to the observations. The disagreement is noticably worse for the decaying simulation, in which cores show highly supersonic infall signatures in their centers that decrease toward their edges, a pattern not seen in the observed regions. This result gives some support to the use of driven turbulence for modeling regions of star formation, but reaching a firm conclusion on the relative merits of driven or decaying turbulence will require more complete data on a larger sample of clouds as well as simulations that include magnetic fields, outflows, and thermal feedback from the protostars.