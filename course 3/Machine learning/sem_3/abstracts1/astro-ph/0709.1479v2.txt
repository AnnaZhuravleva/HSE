It is now routine to measure the weak gravitational lensing shear signal from the mean ellipticity of distant galaxies. However, conversion between ellipticity and shear assumes local linearity of the lensing potential (ie that the spatial derivatives of the shear are small), and this condition is not satisfied in some of the most interesting regions of the sky. We extend a derivation of lensing equations to include higher order terms, and assess the level of biases introduced by assuming that first-order weak lensing theory holds in a relatively strong shear regime. We find that, even in a worst-case scenario, a fully linear analysis is accurate to within 1% outside ~1.07 times the Einstein radius of a lens, by deriving an analytic function that can be used to estimate the applicability of any first-order analysis. The effect is too small to explain the discrepancy between weak- and strong-lensing estimates of the mass of the bullet cluster, and should not impact cluster surveys for the forseeable future. In fact, it means that arclets can be used to measure shears closer to a cluster core than has been generally appreciated. However, at the level of accuracy demanded by future lensing surveys, this bias ought to be considered in measurements of the inner slope of cluster mass distributions and the small-scale end of the mass power spectrum. Both of these are central in determining the relationship between baryonic and dark matter.