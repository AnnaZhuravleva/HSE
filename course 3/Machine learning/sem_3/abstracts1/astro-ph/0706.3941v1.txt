In this paper we investigate the influence of the intrinsic alignment of background galaxies on weak lensing detections of mass concentrations. Specifically, we analyze the number counts of false peaks resulting from intrinsic ellipticities in lensing convergence maps. Including the alignment of source galaxies, the full noise variance from intrinsic ellipticites in convergence $\kappa$-maps can be written as $\sigma^2_0=\sigma^2_{0ran}+\sigma^2_{0corr}$, where $\sigma^2_{0ran}$ is the noise contributed from randomly oriented source galaxies and $\sigma^2_{0corr}$ denotes the additional noise from intrinsic alignments. However, it is observationally difficult to measure $\sigma^2_{0corr}$ and usually only $\sigma^2_{0ran}$ can be estimated in weak lensing observations. Thus the observational signal-to-noise ratio is often defined with respect to $\sigma_{0ran}$, which is denoted as $\nu_{ran}$ in this paper. The true signal-to-noise ratio $\nu$ in terms of $\sigma_0$ is then $\nu=\nu_{ran}/(1+\sigma^2_{0corr}/\sigma^2_{0ran})^{1/2}$. Given a detection threshold on $\nu_{ran}$, a larger value of $\sigma^2_{0corr}/\sigma^2_{0ran}$ leads to a lower threshold on $\nu$ and therefore a larger expected number of false peaks. With $\sigma^2_{0corr}/\sigma^2_{0ran}\sim 10%$, the average number of false peaks with $\nu_{ran}\ge 3.5$ nearly doubles compared to that without considering the alignment, and for $\nu_{ran}\ge 5$, the number is tripled. As a result, the efficiency of weak lensing cluster detection degrades significantly. (Abridged)