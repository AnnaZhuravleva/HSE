We investigate to what extent the temperature dependence of the nuclear symmetry energy can affect the neutronization of the stellar core prior to neutrino trapping during gravitational collapse. To this end, we implement a one-zone simulation to follow the collapse until beta equilibrium is reached and the lepton fraction remains constant. Since the strength of electron capture on the neutron-rich nuclei associated to the supernova scenario is still an open issue, we keep it as a free parameter. We find that the temperature dependence of the symmetry energy consistently yields a small reduction of deleptonization, which corresponds to a systematic effect on the shock wave energetics: the gain in dissociation energy of the shock has a small yet non-negligible value of about 0.4 foe (1 foe = 10^51 erg) and this result is almost independent from the strength of nuclear electron capture. The presence of such a systematic effect and its robustness under changes of the parameters of the one-zone model are significative enough to justify further investigations with detailed numerical simulations of supernova explosions.