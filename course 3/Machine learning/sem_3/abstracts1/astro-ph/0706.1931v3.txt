We calculate the systematic inhomogeneity-induced correction to the cosmological constant that one would infer from an analysis of the luminosities and redshifts of Type Ia supernovae, assuming a homogeneous universe. The calculation entails a post-Newtonian expansion within the framework of second order perturbation theory, wherein we consider the effects of subhorizon density perturbations in a flat, dust dominated universe. Within this formalism, we calculate luminosity distances and redshifts along the past light cone of an observer. The resulting luminosity distance-redshift relation is fit to that of a homogeneous model in order to deduce the best-fit cosmological constant density Omega_Lambda. We find that the luminosity distance-redshift relation is indeed modified, by a small fraction of order 10^{-5}. When fitting this perturbed relation to that of a homogeneous universe, we find that the inferred cosmological constant can be surprisingly large, depending on the range of redshifts sampled. For a sample of supernovae extending from z=0.02 out to z=0.15, we find that Omega_Lambda=0.004. The value of Omega_Lambda has a large variance, and its magnitude tends to get larger for smaller redshifts, implying that precision measurements from nearby supernova data will require taking this effect into account. However, we find that this effect is likely too small to explain the observed value of Omega_Lambda=0.7. There have been previous claims of much larger backreaction effects. By contrast to those calculations, our work is directly related to how observers deduce cosmological parameters from astronomical data.