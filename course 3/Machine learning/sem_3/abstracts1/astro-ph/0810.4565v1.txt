The cosmic ray current-driven (CRCD) instability, predicted by Bell (2004), consists of non-resonant, growing plasma waves driven by the electric current of cosmic rays (CRs) that stream along the magnetic field ahead of both relativistic and non-relativistic shocks. Combining an analytic, kinetic model with one-, two-, and three-dimensional particle-in-cell simulations, we confirm the existence of this instability in the kinetic regime and determine its saturation mechanisms. In the linear regime, we show that, if the background plasma is well magnetized, the CRCD waves grow exponentially at the rates and wavelengths predicted by the analytic dispersion relation. The magnetization condition implies that the growth rate of the instability is much smaller than the ion cyclotron frequency. As the instability becomes non-linear, significant turbulence forms in the plasma. This turbulence reduces the growth rate of the field and damps the shortest wavelength modes, making the dominant wavelength, \lambda_d, grow proportional to the square of the field. At constant CR current, we find that plasma acceleration along the motion of CRs saturates the instability at the magnetic field level such that v_A ~ v_{d,cr}, where v_A is the Alfven velocity in the amplified field, and v_{d,cr} is the drift velocity of CRs. The instability can also saturate earlier if CRs get strongly deflected by the amplified field, which happens when their Larmor radii get close to \lambda_d. We apply these results to the case of CRs in the upstream medium of supernova remnants. Considering only the most energetic CRs that escape from the shock, we obtain that the field amplification factor of ~10 can be reached. This confirms the CRCD instability as a potentially important component of magnetic amplification process in astrophysical shocks.