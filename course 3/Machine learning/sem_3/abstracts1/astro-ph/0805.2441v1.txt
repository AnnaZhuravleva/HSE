We describe the formation and evolution of X-ray cavities in the hot gas of galaxy clusters. The cavities are formed only with relativistic cosmic rays that eventually diffuse into the surrounding gas. We explore the evolution of cavities formed with a wide range of cosmic ray diffusion rates. In previous numerical simulations cavities are formed by injecting ultra-hot but non-relativistic gas which increases the global thermal energy, offsetting radiative losses in the gas and helping to solve the cooling flow problem. Contrary to these results, we find that X-ray cavities formed solely by cosmic rays have a global cooling effect. As the cluster gas is displaced by cosmic rays, a global expansion of the cluster gas occurs with associated cooling that exceeds the heating by shock waves as the cavity forms. Most cosmic rays in our cavity evolutions do not move beyond the cooling radius even after 1 Gyr. The gas density is depressed by cosmic rays, becomes buoyant, and undergoes a significant outward mass transfer within the cooling radius, carrying cosmic rays and relatively low entropy gas to distant regions in the cluster where it remains for times exceeding the local cooling time in the hot gas. This post-cavity mass outflow due to cosmic ray buoyancy may contribute toward solving the cooling flow problem. We describe the energetics, size, stability and buoyant rise of X-ray cavities in detail, showing how each depends on the rate of cosmic ray diffusion.