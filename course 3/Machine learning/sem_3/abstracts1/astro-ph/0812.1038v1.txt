I discuss some theoretical expectations for the synchrotron emission from a relativistic blast-wave interacting with the ambient medium, as a model for GRB afterglows, and compare them with observations. An afterglow flux evolving as a power-law in time, a bright optical flash during/after the burst, and a light-curve break due to a tight ejecta collimation are the major predictions that were confirmed observationally, but it should be recognized that light-curve decay indices are not correlated with the spectral slopes (as would be expected), optical flashes are quite rare, and jet-breaks harder to find in Swift X-ray afterglows.   The slowing of the early optical flux decay rate is accompanied by a spectral evolution, indicating that the emission from ejecta (energized by the reverse shock) is dominant in the optical over that from the forward shock (which energizes the ambient medium) only up to 1 ks. However, a long-lived reverse shock is required to account for the slow radio flux decays observed in many afterglows after ~10 day.   X-ray light-curve plateaus could be due to variations in the average energy-per-solid-angle of the blast-wave, confirming to two other anticipated features of GRB outflows: energy injection and angular structure. The latter is also the more likely origin of the fast-rises seen in some optical light-curves. To account for the existence of both chromatic and achromatic afterglow light-curve breaks, the overall picture must be even more complex and include a new mechanism that dominates occasionally the emission from the blast-wave: either late internal shocks or scattering (bulk and/or inverse-Compton) of the blast-wave emission by an outflow interior to it.