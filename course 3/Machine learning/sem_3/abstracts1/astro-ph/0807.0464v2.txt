We analyse the local variance effect in the standard method for detecting the integrated Sachs-Wolfe effect (ISW) via cross-correlating the cosmic microwave background (CMB) with the large-scale structure (LSS). Local variance is defined as the systematic noise in the ISW detection that originates in the realisation of the matter distribution in the observed Universe. We show that the local variance contributes about 11 per cent to the total variance in the standard method, if a perfect and complete LSS survey up to z ~ 2 is assumed. Due to local variance, the estimated detection significance and cosmological parameter constraints in the standard method are biased. In this work, we present an optimal method of how to reduce the local variance effect in the ISW detection by working conditional on the LSS-data. The variance of the optimal method, and hence the signal-to-noise ratio, depends on the actual realisation of the matter distribution in the observed Universe. We show that for an ideal galaxy survey, the average signal-to-noise ratio is enhanced by about 7 per cent in the optimal method, as compared to the standard method. Furthermore, in the optimal method there is no need to estimate the covariance matrix by Monte Carlo simulations as in the standard method, which saves time and increases the accuracy. Finally, we derive the correct joint likelihood function for cosmological parameters given CMB- and LSS-data within the linear LSS formation regime, which includes a small coupling of the two datasets due to the ISW effect.