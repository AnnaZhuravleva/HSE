We investigate the dependence of the total-infrared (TIR) to UV luminosity ratio method for calculating the UV dust attenuation A(UV) from the age of the underlying stellar populations by using a library of spectral energy distributions for galaxies with different star formation histories. Our analysis confirms that the TIR/UV vs. A(UV) relation varies significantly with the age of the underlying stellar population: i.e. for the same TIR/UV ratio, systems with low specific star formation rate (SSFR) suffer a lower UV attenuation than starbursts. Using a sample of nearby field and cluster spiral galaxies we show that the use of a standard (i.e. age independent) TIR/UV vs. A(UV) relation leads to a systematic overestimate up to 2 magnitudes of the amount of UV dust attenuation suffered by objects with low SSFR and in particular HI-deficient star forming cluster galaxies. This result points out that the age independent $TIR/UV$ vs. $A(UV)$ relation cannot be used to study the UV properties of large samples of galaxies including low star-forming systems and passive spirals. Therefore we give some simple empirical relations from which the UV attenuation can be estimated taking into account its dependence on the age of the stellar populations, providing a less biased view of UV properties of galaxies.