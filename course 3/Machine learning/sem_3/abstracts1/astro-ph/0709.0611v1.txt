A theory is developed to describe the nonlocal effect of spacetime quantization on position measurements transverse to macroscopic separations. Spacetime quantum states close to a classical null trajectory are approximated by plane wavefunctions of Planck wavelength (l_P) reference beams; these are used to connect transverse position operators at macroscopically separated events. Transverse positions of events with null spacetime separation, but separated by macroscopic spatial distance $L$, are shown to be quantum conjugate observables, leading to holographic indeterminacy and a new uncertainty principle, a lower bound on the standard deviation of relative transverse position \Delta x_\perp > \sqrt{l_PL} or angular orientation \Delta\theta > \sqrt{l_P/L}. The resulting limit on the number of independent degrees of freedom is shown to agree quantitatively with holographic covariant entropy bounds derived from black hole physics and string theory. The theory predicts a universal ``holographic noise'' of spacetime, appearing as shear perturbations with a frequency-independent power spectral density S_H=l_P/c, or in equivalent metric perturbation units, h_{H,rms} \sqrt{l_P/c} = 2.3 \times 10^{-22} /\sqrt{Hz}. If this description of holographic phenomenology is valid, interferometers with current technology could undertake direct quantitative studies of quantum gravity.