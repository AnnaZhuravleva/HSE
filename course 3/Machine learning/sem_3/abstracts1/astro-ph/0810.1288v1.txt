In this paper we revisit the arguments for the basis of the time evolution of the flares expected to arise when a star is disrupted by a supermassive black hole. We present a simple analytic model relating the lightcurve to the internal density structure of the star. We thus show that the standard lightcurve proportional to $t^{-5/3}$ only holds at late times. Close to the peak luminosity the lightcurve is shallower, deviating more strongly from $t^{-5/3}$ for more centrally concentrated (e.g. solar--type) stars. We test our model numerically by simulating the tidal disruption of several stellar models, described by simple polytropic spheres with index $\gamma$. The simulations agree with the analytical model given two considerations. First, the stars are somewhat inflated on reaching pericentre because of the effective reduction of gravity in the tidal field of the black hole. This is well described by a homologous expansion by a factor which becomes smaller as the polytropic index becomes larger. Second, for large polytropic indices wings appear in the tails of the energy distribution, indicating that some material is pushed further away from parabolic orbits by shocks in the tidal tails. In all our simulations, the $t^{-5/3}$ lightcurve is achieved only at late stages. In particular we predict that for solar type stars, this happens only after the luminosity has dropped by at least two magnitudes from the peak. We discuss our results in the light of recent observations of flares in otherwise quiescent galaxies and note the dependence of these results on further parameters, such as the star/hole mass ratio and the stellar orbit.