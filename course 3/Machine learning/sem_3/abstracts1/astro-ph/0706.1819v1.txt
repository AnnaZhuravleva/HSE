Afterglows of gamma-ray bursts are believed to require magnetic fields much stronger than that of the compressed pre-shock medium. As an alternative to microscopic plasma instabilities, we propose amplification of the field by macroscopic turbulence excited by the interaction of the shock with a clumpy pre-shock medium, for example a stellar wind. Using a recently developed formalism for localized perturbations to an ultra-relativistic shock, we derive constraints on the lengthscale, amplitude, and volume filling factor of density clumps required to produce a given magnetic energy fraction within the expansion time of the shock, assuming that the energy in the field achieves equipartion with the turbulence. Stronger and smaller-scale inhomogeneities are required for larger shock Lorentz factors. Hence it is likely that the magnetic energy fraction evolves as the shock slows. This could be detected by monitoring the synchrotron cooling frequency if the radial density profile ahead of the shock, smoothed over clumps, is known.