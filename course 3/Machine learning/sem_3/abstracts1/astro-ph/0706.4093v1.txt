We examine deep far-ultraviolet (1600 Angstrom) imaging of the Hubble Deep Field-North (HDFN) and the Hubble Ultra Deep Field (HUDF) to search for leaking Lyman continuum radiation from starburst galaxies at z~1.3. There are 21 (primarily sub-L*) galaxies with spectroscopic redshifts between 1.1<z<1.5 and none are detected in the far-UV. We fit stellar population templates to the galaxies' optical/near-infrared SEDs to determine the starburst age and level of dust attenuation, giving an accurate estimate of the intrinsic Lyman continuum ratio, f_1500/f_700, and allowing a conversion from f_700 limits to relative escape fractions. We show that previous high-redshift studies may have underestimated the amplitude of the Lyman Break, and thus the relative escape fraction, by a factor of ~2. Once the starburst age and intergalactic HI absorption are accounted for, 18 galaxies in our sample have limits to the relative escape fraction, f_esc,rel < 1.0 with some limits as low as f_esc,rel < 0.10 and a stacked limit of f_esc,rel < 0.08. This demonstrates, for the first time, that most sub-L* galaxies at high redshift do not have large escape fractions. When combined with a similar study of more luminous galaxies at the same redshift we show that, if all star-forming galaxies at z~1 have similar relative escape fractions, the value must be less than 0.14 (3 sigma). We also show that less than 20% (3 sigma) of star-forming galaxies at z~1 have relative escape fractions near unity. These limits contrast with the large escape fractions found at z~3 and suggest that the average escape fraction has decreased between z~3 and z~1. (Abridged)