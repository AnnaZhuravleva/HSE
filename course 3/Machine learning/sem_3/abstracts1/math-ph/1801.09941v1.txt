We present and establish large deviations principles for general multivariate renewal-reward processes associated with a classical discrete-time renewal process. A renewal-reward process describes a cumulative reward over time, supposing that a broad-sense multivariate reward is obtained at each occurrence of the event that is renewed under the renewal process. We consider both the standard model and a constrained model that is constructed conditioning on the event that one of the renewals occurs at a predetermined time. With a different interpretation of the time coordinate, the constrained renewal model includes several important models of statistical mechanics, such as the model of polymer pinning, the Poland-Scheraga model of DNA denaturation, the Wako-Sait\^o-Mu\~noz-Eaton model of protein folding, and the Tokar-Dreyss\'e model of strained epitaxy. We attack the problem of large deviations in constrained renewal models by an argument based on convexity and super-additivity. Then, we transfer results to standard renewal processes by resorting to conditioning. In the context of constrained renewal models, we also propose an explicit application of the general theory to deterministic rewards that grow no faster than the time elapsed between two successive occurrences of the renewed event. This type of rewards codifies the extensive variables of statistical mechanics.