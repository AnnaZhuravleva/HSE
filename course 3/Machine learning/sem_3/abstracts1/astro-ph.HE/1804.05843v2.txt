Recently the EDGES experiment has claimed the detection of an absorption feature centered at 78 MHz. When interpreted as a signature of cosmic dawn, this feature appears at the correct wavelength (corresponding to a redshift range of $z\approx15-20$) but is larger by at least a factor of two in amplitude compared to the standard 21-cm models. One way to explain the excess radio absorption is by the enhancement of the diffuse radio background at $\nu = 1.42$ GHz ($\lambda=21$ cm) in the rest frame of the absorbing neutral hydrogen. Astrophysical scenarios, based on the acceleration of relativistic electrons by accretion on to supermassive black holes (SMBHs) and by supernovae (SN) from first stars, have been proposed to produce the enhanced radio background via synchrotron emission. In this Letter we show that either the synchrotron or the inverse-Compton (IC) cooling time for such electrons is at least three orders of magnitude shorter than the duration of the EDGES signal centered at $z \approx 17$, irrespective of the magnetic field strength. The synchrotron radio emission at 1.42 GHz due to rapidly cooling electrons is $\sim 10^3$ times smaller than the non-cooling estimate. Thus astrophysical scenarios for excess radio background proposed to explain the EDGES signal are comfortably ruled out.