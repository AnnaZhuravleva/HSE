General relativity's no-hair theorem states that isolated astrophysical black holes are described by only two numbers: mass and spin. As a consequence, there are strict relationships between the frequency and damping time of the different modes of a perturbed Kerr black hole. Testing the no-hair theorem has been a longstanding goal of gravitational-wave astronomy. The recent detection of gravitational waves from black hole mergers would seem to make such tests imminent. We investigate how constraints on black hole ringdown parameters scale with the loudness of the ringdown signal---subject to the constraint that the post-merger remnant must be allowed to settle into a perturbative, Kerr-like state. In particular, we require that---for a given detector---the gravitational waveform predicted by numerical relativity is indistinguishable from an exponentially damped sine after time $t^\text{cut}$. By requiring the post-merger remnant to settle into such a perturbative state, we find that confidence intervals for ringdown parameters do not necessarily shrink with louder signals. In at least some cases, more sensitive measurements probe later times without necessarily providing tighter constraints on ringdown frequencies and damping times. Preliminary investigations are unable to explain this result in terms of a numerical relativity artifact.