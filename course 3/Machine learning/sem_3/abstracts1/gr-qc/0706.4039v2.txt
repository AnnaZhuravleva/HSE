We search for possible time lags caused by quantum gravitational (QG) effects using gamma-ray bursts (GRBs) detected by INTEGRAL. The advantage of this satellite is that we have at our disposal the energy and arrival time of every detected single photon, which enhances the precision of the time resolution. We present a new method for seeking time lags in unbinned data using a maximum likelihood method and support our conclusions with Monte Carlo simulations. The analysis of the data yields a mass scale well below the Planck mass whose value may however increase if better statistics of GRBs were available. Furthermore, we disagree with previous studies in which a non-monotonic function of the redshift was used to perform a linear fit.