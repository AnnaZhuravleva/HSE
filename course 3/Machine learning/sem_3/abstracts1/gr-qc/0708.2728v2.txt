The problem of the detection and mapping of a stochastic gravitational wave background (SGWB), either of cosmological or astrophysical origin, bears a strong semblance to the analysis of CMB anisotropy and polarization. The basic statistic we use is the cross-correlation between the data from a pair of detectors. In order to `point' the pair of detectors at different locations one must suitably delay the signal by the amount it takes for the gravitational waves (GW) to travel to both detectors corresponding to a source direction. Then the raw (observed) sky map of the SGWB is the signal convolved with a beam response function that varies with location in the sky. We first present a thorough analytic understanding of the structure of the beam response function using an analytic approach employing the stationary phase approximation. The true sky map is obtained by numerically deconvolving the beam function in the integral (convolution) equation. We adopt the maximum likelihood framework to estimate the true sky map that has been successfully used in the broadly similar, well-studied CMB map making problem. We numerically implement and demonstrate the method on simulated (unpolarized) SGWB for the radiometer consisting of the LIGO pair of detectors at Hanford and Livingston. We include `realistic' additive Gaussian noise in each data stream based on the LIGO-I noise power spectral density. The extension of the method to multiple baselines and polarized GWB is outlined. In the near future the network of GW detectors, including the Advanced LIGO and Virgo detectors that will be sensitive to sources within a thousand times larger spatial volume, could provide promising data sets for GW radiometry.