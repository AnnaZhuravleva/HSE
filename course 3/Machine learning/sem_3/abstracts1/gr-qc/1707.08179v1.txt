Owing to the analogy with the ordinary photons in the visible range of the electromagnetic spectrum, the Glauber theory is generalized to address the quantum coherence of the gauge field fluctuations parametrically amplified during an inflationary stage of expansion. The first and second degrees of quantum coherence of relic photons are then computed beyond the effective horizon defined by the evolution of the susceptibility. In the zero-delay limit the Hanbury Brown-Twiss correlations exhibit a super-Poissonian statistics which is however different from the conventional results of the single-mode approximation customarily employed, in quantum optics, to classify the coherence properties of visible light. While in the case of large-scale curvature perturbations the degrees of quantum coherence coincide with the naive expectation of the single-mode approximation, the net degree of second-order coherence computed for the relic photons diminishes thanks to the effect of the polarizations. We suggest that the Hanbury Brown-twiss correlations are probably the only tool to assess the quantum or classical origin of the large-scale magnetic fluctuations and of the corresponding curvature perturbations.