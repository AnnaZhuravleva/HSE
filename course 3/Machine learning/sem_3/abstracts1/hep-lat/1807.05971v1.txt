A novel lattice QCD data analysis approach using machine learning (ML) technique is proposed. Based on the statistical correlations between the observables measured on the lattice, ML is trained to predict an unmeasured observable ($O$) from the measured observables ($\mathbf{X}$). The prediction error is estimated using cross-validation. The approach is demonstrated for two different lattice QCD calculations using the Boosted decision tree (BDT) regression ML algorithm: (1) prediction of the nucleon three-point correlation functions from the two-point correlation functions, and (2) prediction of charge-parity violating (CPV) phase of the neutron states for the quark chromo electric dipole moment interactions from the regular two-point correlation functions calculated without CPV interactions. After trained on a small training data set (about 20% of total number of configurations) that contains both the $O$ and $\mathbf{X}$ measurements, the BDT regression algorithm successfully predicted the $O$ for the rest of the configurations only using $\mathbf{X}$