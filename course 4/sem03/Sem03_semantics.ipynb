{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Sem03_semantics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnaZhuravleva/HSE/blob/master/course%204/sem03/Sem03_semantics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqhJx9oqrhbd",
        "colab_type": "code",
        "outputId": "8958ad36-eb62-4df7-fd9a-b3c2da27fad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu6zuXZo0LLv",
        "colab_type": "code",
        "outputId": "4c8a4996-aff9-439e-c6bd-c1267c0ce0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "import gensim\n",
        "import zipfile\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import pymorphy2\n",
        "from scipy import spatial\n",
        "import re\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "\n",
        "from google.colab import drive\n",
        "import time\n",
        "from time import time\n",
        "\n",
        "pmm = pymorphy2.MorphAnalyzer()\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP5OgEtO7Ovz",
        "colab_type": "code",
        "outputId": "c09520c7-cef8-4463-8347-2bb42ccd4e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "elmo_path = '/content/drive/My Drive/Colab Notebooks/infosearch/sem3/elmo'\n",
        "project_path = '/content/drive/My Drive/Colab Notebooks/infosearch/sem3/'\n",
        "sys.path.append(project_path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiXYCZCR89bM",
        "colab_type": "text"
      },
      "source": [
        "# **FastText Search**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO-FntDo6AFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# urllib.request.urlretrieve(\"http://vectors.nlpl.eu/repository/11/181.zip\", \"/content/drive/My Drive/Colab Notebooks/infosearch/181.zip\")\n",
        "# z = zipfile.ZipFile('/content/drive/My Drive/Colab Notebooks/infosearch/sem3/181.zip', 'r')\n",
        "# z.extractall('/content/drive/My Drive/Colab Notebooks/infosearch/sem3/fasttext/')\n",
        "collection = '/content/drive/My Drive/Colab Notebooks/infosearch/sem3/collection.csv'\n",
        "model = '/content/drive/My Drive/Colab Notebooks/infosearch/sem3/fasttext/model.model'\n",
        "corpus = '/content/drive/My Drive/Colab Notebooks/infosearch/sem3/quora_question_pairs_rus.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOLsTJnDFcyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FastTextSearch:\n",
        "\n",
        "    def __init__(self, model, collection, corpus):\n",
        "        self.model = gensim.models.KeyedVectors.load(model)\n",
        "        self.collection = pd.read_csv(collection) # возьмем тот же файл, что и в прошлой домашке\n",
        "        self.corpus = self.collection['question2']\n",
        "        self.questions = pd.read_csv(corpus)['question1']\n",
        "        self.test_corpus = self.test_data()\n",
        "        self.matrix = self.index_fasttext()\n",
        "        \n",
        "    def fasttext_search(self, query):\n",
        "\n",
        "      lemmas_vectors = np.zeros((len(query), self.model.vector_size))\n",
        "      vec = np.zeros((self.model.vector_size,))\n",
        "\n",
        "      for idx, lemma in enumerate(query):\n",
        "        if lemma in self.model.vocab:\n",
        "          lemmas_vectors[idx] = self.model.wv[lemma]\n",
        "        else:\n",
        "          pass\n",
        "\n",
        "      if lemmas_vectors.shape[0] is not 0:\n",
        "          vec = np.mean(lemmas_vectors, axis=0)\n",
        "          \n",
        "      return vec\n",
        "\n",
        "    def index_fasttext(self):\n",
        "        matrix_fasttext = np.zeros((self.corpus.shape[0], self.model.vector_size))\n",
        "        start_time = time()\n",
        "        for row, query in enumerate(self.corpus):  \n",
        "          vector = self.fasttext_search(query.split()) # наш корпус уже нормализован\n",
        "          for idx, cell in enumerate(vector):\n",
        "              matrix_fasttext[row][idx] = cell\n",
        "        print(f'Indexing FastTextSearch takes {time() - start_time} sec')\n",
        "        return matrix_fasttext\n",
        "\n",
        "    def simple_preproc(self, query):\n",
        "        return [pmm.normal_forms(word)[0] for word in nltk.word_tokenize(query)]\n",
        "        \n",
        "    def test_data(self):\n",
        "        test_data = []\n",
        "        for question in self.questions[:3]:\n",
        "            question = self.simple_preproc(question)\n",
        "            vector = self.fasttext_search(question)\n",
        "            test_data.append(vector)\n",
        "        return test_data\n",
        "\n",
        "    def testing(self, n):\n",
        "        vec = self.test_corpus[0]\n",
        "        res = {}\n",
        "        for i in range(n):\n",
        "          row = self.matrix[i]\n",
        "          cos_sim = spatial.distance.cosine(row, vec)\n",
        "          res[i] = cos_sim\n",
        "\n",
        "        res = sorted(res.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bMU72weCDMQ",
        "colab_type": "code",
        "outputId": "0790f547-1b86-42be-f6b4-89cb987af69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "fts = FastTextSearch(model=model, corpus=corpus, collection=collection)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Indexing FastTextSearch takes 73.68462038040161 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5klVLmDLHaPS",
        "colab_type": "code",
        "outputId": "335e5d83-13ac-47ae-ff52-ba956b97ca9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "fts.testing()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(75, 0.826882691091914),\n",
              " (1206, 0.8187299962122366),\n",
              " (547, 0.8023287962484263),\n",
              " (608, 0.7918055085531388),\n",
              " (1929, 0.7889931007593103)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTlvSW9GB6TJ",
        "colab_type": "text"
      },
      "source": [
        "# **ELMO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHdJWE3Alrfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from elmo_helpers import tokenize, get_elmo_vectors, load_elmo_embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHJaix0TI57O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ElmoSearch:\n",
        "  \n",
        "  def __init__(self):\n",
        "    tf.reset_default_graph()\n",
        "    self.batcher, self.sentence_character_ids, self.elmo_sentence_input = \\\n",
        "    load_elmo_embeddings(elmo_path)\n",
        "    self.vectors = []\n",
        "    \n",
        "  def build_vec(self, sentences):\n",
        "     with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        elmo_vectors = get_elmo_vectors(\n",
        "            sess, sentences, self.batcher, self.sentence_character_ids,\n",
        "            self.elmo_sentence_input)\n",
        "        \n",
        "        print(f'Tensor shape: {elmo_vectors.shape}')\n",
        "        results = []\n",
        "        for vect, sent in zip(elmo_vectors, sentences):\n",
        "          results.append(np.mean(vect[:len(sent), :], axis=0))\n",
        "        \n",
        "        return results\n",
        "    \n",
        "  def indexing(self, sentences):\n",
        "    with tf.Session() as sess:\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      start = time()\n",
        "      sentences = [tokenize(sent) for sent in sentences]\n",
        "      for sent in sentences:\n",
        "        sent_vec = self.build_vec([sent])\n",
        "        self.vectors.append(sent_vec[0])\n",
        "        \n",
        "      print(f'=====\\n'\\\n",
        "            f'ElmoSearch Indexing takes {time() - start} sec'\\\n",
        "            f'for {len(sentences)} docs')\n",
        "      return self.vectors\n",
        "    \n",
        "  def simple_preproc(self, query):\n",
        "      return [pmm.normal_forms(word)[0] for word in nltk.word_tokenize(query)]\n",
        "    \n",
        "  def elmo_search(self, query):\n",
        "    query = self.simple_preproc(query)\n",
        "    query_vec = self.build_vec([query])\n",
        "    \n",
        "      \n",
        "      \n",
        "    \n",
        "      \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDI07FFBkQ8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35ac648f-cadd-4677-a8fe-64a0f122d819"
      },
      "source": [
        "np.mean([[1,2,3], [4,5,6], [7,8,9]], axis=0)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4., 5., 6.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JedfRS1o4s8Q",
        "colab_type": "code",
        "outputId": "e280fde8-9962-4472-d5cc-df3f99cdf49b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "els = ElmoSearch()\n",
        "els.indexing(pd.read_csv(collection)['question2'][:2])\n",
        "els.elmo_search('зарплаты Индии')"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentences in this batch: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor shape: (1, 12, 1024)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Sentences in this batch: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor shape: (1, 8, 1024)\n",
            "=====\n",
            "ElmoSearch Indexing takes 4.347093105316162 secfor 2 docs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Sentences in this batch: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor shape: (1, 2, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ive3mQIinWUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b8c3533-f786-4eb4-db5b-db1e5fedcd63"
      },
      "source": [
        "len(tmp2[0])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKwMoY8t0LMV",
        "colab_type": "text"
      },
      "source": [
        "## Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9Fxfkzg0LMX",
        "colab_type": "text"
      },
      "source": [
        "Реализуйте поиск по [Quora question pairs](https://www.kaggle.com/loopdigga/quora-question-pairs-russian) на нескольких векторных моделях\n",
        "\n",
        "    1. fasttext, модель ruscorpora_none_fasttextskipgram_300_2_2019\n",
        "    2. elmo, модель ruwikiruscorpora_lemmas_elmo_1024_2019\n",
        "    3. bert*, RuBERT - необязательно\n",
        "   \n",
        "Первые две обученные модели можно скачать на сайте [rusvectores](https://rusvectores.org/en/models/).\n",
        "\n",
        "BERT делать необязательно, но если сделаете, 6 за курс у вас автоматом. Модель можно [найти тут](http://docs.deeppavlov.ai/en/master/features/models/bert.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVLs36sU0LMY",
        "colab_type": "text"
      },
      "source": [
        "### __Задача 1__:    \n",
        "Сравните время индексации корпуса для каждой модели "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIuM1qoU0LMc",
        "colab_type": "text"
      },
      "source": [
        "### __Задача 2__:    \n",
        "Выведите качество поиска для каждой модели +  BM25 для сравнения\n",
        "\n",
        "Качество оцениваем так же, как в прошлом задании:\n",
        "    - если в топ-5 результатов выдачи попал хоть один релевантный документ, выдача точная\n",
        "    - если в топ-5 нет ни одного релеватного документа, выдача получает 0\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiV-H9WB0LMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}